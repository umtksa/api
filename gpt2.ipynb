{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "yszQXlBwI_cM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Data klasörünü oluştur\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "while True:\n",
        "    # Kullanıcıdan Wikipedia URL'sini al\n",
        "    url = input(\"URL or exit : \")\n",
        "\n",
        "    # Çıkış komutunu kontrol et\n",
        "    if url.lower() in ['exit', 'quit']:\n",
        "        print(\"Program sonlandırılıyor.\")\n",
        "        break\n",
        "\n",
        "    # Sayfa içeriğini al\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(\"URL'den veri alınamadı.\")\n",
        "        continue\n",
        "\n",
        "    # Sayfa içeriğini BeautifulSoup ile ayrıştır\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Sayfa başlığını al\n",
        "    title = soup.find('h1', {'id': 'firstHeading'}).get_text()\n",
        "\n",
        "    # Ana içerik kısmını seç (Vikipedi sayfalarındaki ana metin genellikle <p> etiketlerinde bulunur)\n",
        "    content = soup.find_all('p')\n",
        "\n",
        "    # Metni birleştir\n",
        "    text = \"\\n\".join([para.get_text().strip() for para in content])\n",
        "\n",
        "    # Boş satırları temizle\n",
        "    cleaned_text = \"\\n\".join(line for line in text.splitlines() if line.strip())\n",
        "\n",
        "    # Başlık için geçerli bir dosya adı oluştur\n",
        "    filename = f\"{title}.txt\".replace('/', '_').replace('\\\\', '_')\n",
        "\n",
        "    # Dosyayı data klasörüne kaydet\n",
        "    filepath = os.path.join('data', filename)\n",
        "    with open(filepath, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "    print(f\"Metin '{filepath}' dosyasına kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yXPY84Byp9Q",
        "outputId": "d9e60d16-8474-46db-d4f2-51cf6877b2b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL or exit : https://tr.wikipedia.org/wiki/T.C._Resm%C3%AE_Gazete\n",
            "Metin 'data/T.C. Resmî Gazete.txt' dosyasına kaydedildi.\n",
            "URL or exit : https://tr.wikipedia.org/wiki/T%C3%BCrkiye_h%C3%BCk%C3%BBmetleri_listesi\n",
            "Metin 'data/Türkiye hükûmetleri listesi.txt' dosyasına kaydedildi.\n",
            "URL or exit : https://tr.wikipedia.org/wiki/T%C3%BCrkiye_cumhurba%C5%9Fkan%C4%B1\n",
            "Metin 'data/Türkiye cumhurbaşkanı.txt' dosyasına kaydedildi.\n",
            "URL or exit : https://tr.wikipedia.org/wiki/T%C3%BCrkiye_B%C3%BCy%C3%BCk_Millet_Meclisi\n",
            "Metin 'data/Türkiye Büyük Millet Meclisi.txt' dosyasına kaydedildi.\n",
            "URL or exit : https://tr.wikipedia.org/wiki/T%C3%BCrk%C3%A7e\n",
            "Metin 'data/Türkçe.txt' dosyasına kaydedildi.\n",
            "URL or exit : https://tr.wikipedia.org/wiki/T%C3%BCrkiye\n",
            "Metin 'data/Türkiye.txt' dosyasına kaydedildi.\n",
            "URL or exit : https://tr.wikipedia.org/wiki/Osmanl%C4%B1_%C4%B0mparatorlu%C4%9Fu\n",
            "Metin 'data/Osmanlı İmparatorluğu.txt' dosyasına kaydedildi.\n",
            "URL or exit : exit\n",
            "Program sonlandırılıyor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "# Data klasöründeki tüm .txt dosyalarını listele\n",
        "data_folder = 'data'\n",
        "text_files = [f for f in os.listdir(data_folder) if f.endswith('.txt')]\n",
        "\n",
        "# Tüm txt dosyalarını yükle ve içeriklerini birleştir\n",
        "all_text_data = \"\"\n",
        "for file_name in text_files:\n",
        "    file_path = os.path.join(data_folder, file_name)\n",
        "    print(f\"Şu an {file_name} ile işlem yapıyorum.\")\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        all_text_data += file.read() + \"\\n\"\n",
        "\n",
        "# Köşeli parantez içindeki tüm rakamları sil\n",
        "cleaned_text = re.sub(r'\\[\\d+\\]', '', all_text_data)\n",
        "\n",
        "# Boş satırları temizle\n",
        "cleaned_text = re.sub(r'\\n\\s*\\n', '\\n', cleaned_text)\n",
        "\n",
        "# Temizlenmiş datayı data.txt olarak kaydet\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(cleaned_text.strip())  # Strip, başındaki ve sonundaki boşlukları da temizler\n",
        "\n",
        "print(\"Tüm veriler temizlendi ve data.txt dosyasına kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUZvURogl63t",
        "outputId": "355c4b74-17db-42f4-e24e-64f42dd7e575"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Şu an Haliç.txt ile işlem yapıyorum.\n",
            "Şu an Büyükada.txt ile işlem yapıyorum.\n",
            "Şu an Fransızca.txt ile işlem yapıyorum.\n",
            "Şu an Tünel.txt ile işlem yapıyorum.\n",
            "Şu an İçerenköy, Ataşehir.txt ile işlem yapıyorum.\n",
            "Şu an Matbaacılık.txt ile işlem yapıyorum.\n",
            "Şu an Bizans İmparatorluğu.txt ile işlem yapıyorum.\n",
            "Şu an Türkiye Büyük Millet Meclisi.txt ile işlem yapıyorum.\n",
            "Şu an T.C. Resmî Gazete.txt ile işlem yapıyorum.\n",
            "Şu an İstanbul.txt ile işlem yapıyorum.\n",
            "Şu an I. Dünya Savaşı.txt ile işlem yapıyorum.\n",
            "Şu an Türkiye cumhurbaşkanı.txt ile işlem yapıyorum.\n",
            "Şu an Türkiye hükûmetleri listesi.txt ile işlem yapıyorum.\n",
            "Şu an İstanbul'un Fethi.txt ile işlem yapıyorum.\n",
            "Şu an Fransa.txt ile işlem yapıyorum.\n",
            "Şu an İstanbul'un ilçeleri.txt ile işlem yapıyorum.\n",
            "Şu an Anadolu Yakası.txt ile işlem yapıyorum.\n",
            "Şu an Osmanlı İmparatorluğu.txt ile işlem yapıyorum.\n",
            "Şu an İstanbul Büyükşehir Belediyesi.txt ile işlem yapıyorum.\n",
            "Şu an Marmara Denizi.txt ile işlem yapıyorum.\n",
            "Şu an Türkiye.txt ile işlem yapıyorum.\n",
            "Şu an Karaköy.txt ile işlem yapıyorum.\n",
            "Şu an Türkçe.txt ile işlem yapıyorum.\n",
            "Şu an I. Konstantin.txt ile işlem yapıyorum.\n",
            "Şu an Mimar Sinan.txt ile işlem yapıyorum.\n",
            "Şu an İstanbul Metrosu.txt ile işlem yapıyorum.\n",
            "Şu an Adalar.txt ile işlem yapıyorum.\n",
            "Tüm veriler temizlendi ve data.txt dosyasına kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "j7z2UzPZEQP9",
        "outputId": "cf42ab11-8d17-499c-f218-fa002c52be78"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  6/684 00:21 < 1:01:47, 0.18 it/s, Epoch 0.01/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dc185d0e167c>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Modeli kaydet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3322\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2151\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Eğitimi burda hallediyoruz\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# Model ve tokenizer'ı yükle\n",
        "model_name = \"gpt2\"  # veya daha küçük bir versiyonu: \"gpt2-small\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Veri kümesini oluştur\n",
        "def load_dataset(file_path, tokenizer, block_size=128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=file_path,\n",
        "        block_size=block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# data.txt dosyasını oku ve veri kümesini yükle\n",
        "train_dataset = load_dataset(\"data.txt\", tokenizer)\n",
        "\n",
        "# Veri hazırlayıcı ve eğitim argümanlarını ayarla\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ahraz\",  # Modelin kaydedileceği dizin\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,  # Eğitim döngüsü sayısı\n",
        "    per_device_train_batch_size=2,  # Eğitim sırasında her cihazda batch boyutu\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Trainer ile modeli eğit\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Modeli kaydet\n",
        "model.save_pretrained(\"./ahraz\")\n",
        "tokenizer.save_pretrained(\"./ahraz\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Model ve tokenizer'ı yükle\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./ahraz\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./ahraz\")\n",
        "\n",
        "def chat(input_text):\n",
        "    # Girişleri encode et\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Attention mask oluştur\n",
        "    attention_mask = torch.ones(inputs.shape, dtype=torch.long)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        attention_mask=attention_mask,  # Attention mask'ı ekle\n",
        "        max_length=80,      # Yanıtın maksimum uzunluğu\n",
        "        num_return_sequences=1,  # Döndürülecek yanıt sayısı\n",
        "        do_sample=True,      # Sampling (örnekleme) modunu aktif et\n",
        "        temperature=0.7,     # Rastgelelik oranı\n",
        "        top_k=50,            # En yüksek olasılıklı token'ları dikkate al\n",
        "        top_p=0.85,          # Nucleus sampling için olasılık eşikleri\n",
        "        pad_token_id=tokenizer.eos_token_id  # Padding token'ı ayarla\n",
        "    )\n",
        "\n",
        "    # Yanıtı decode et\n",
        "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Soruyu yanıtın başından çıkar\n",
        "    response = decoded_output[len(input_text):].strip()\n",
        "    #response = decoded_output\n",
        "\n",
        "    return response\n",
        "\n",
        "# Sohbeti başlat\n",
        "while True:\n",
        "    user_input = input(\"you: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
        "        print(\"ahraz: Görüşürüz!\")\n",
        "        break\n",
        "    response = chat(user_input)\n",
        "    print(\"ahraz:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "Ktx31u2LuySt",
        "outputId": "6f7a4b0a-dee2-44d4-f888-2646f0f2a787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you: denizlerdeki konumu nedir\n",
            "ahraz: denizlerdeki konumu nedir. Türkiye'de üzerindeki konumu nedeniğindeki ve ölçümüştür. Türkiye'de üzerindeki konumu nedeniğindeki, konumu nedeniğindeki ve ölçümüştür. Türkiye'nin konumu nedeniğindeki konumu yer alır.[297] Türkiye'nin konumu nedeniğindeki konumu yer alır.[298] Türkiye'nin konumu nedeniğindeki konumu yer alır.[299] Türkiye'nin konumu nedeniğindeki konumu yer alır.[300] Türkiye'nin konumu nedeniğindeki konumu yer alır.[301] Türkiye'nin konumu nedeniğindeki konumu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9423410754e9>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Sohbeti başlat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ahraz: Görüşürüz!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}